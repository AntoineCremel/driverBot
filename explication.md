# Explication de l'aspect machine learning de notre projet

L'aspect novateur du Deep Learning que nous avons intégré à notre système repose sur sa simplicité. Nous avons choisi volontairement de nous consacrer sur l'aspect reconnaissance d'image de la voituire autonome. Pour chaque situation, la responsabilité de notre réseau est simplement de regarder l'image envoyée par la caméra et de déterminer quelle direction est la plus appropriée à choisir entre Forward (en avant), Backward (en arrière), Right (à droite) ou Left (à gauche). Au final, notre réseau a une mission de classification d'image.

L'architecture que nous avons choisi pour notre réseau reflète cette contrainte. Noux nous sommes orientés vers une architecture de Convolutional Neural Network, un type de réseau qui donne de très bons résultats pour ce genre de tâches. Dans ce genre d'architectures, les premières couches ne sont pas des couches densément connectées comme c'est le cas sur les réseaux de neurone classiques. À la place, ces couches appliquent des filtres et tentent de reconnaître la présence ou l'absence de formes sur l'image qu'on leur communique. L'avantage indéniable de ce genre de système est qu'il est peu gourmand en robuste et est plus robuste à des problèmes comme le changement de luminosité.

Après les plusiseurs couches de convolution, notre réseau arrive sur deux couches densément connectées. La dernière de ces couches contient tout juste 4 "neurones", un pour chacun des résultats possibles pour une image. La fonction d'activation que nous utilisons pour cette dernière couche est celle du softmax, qui va faire tendre le résultat à avoir une somme de 1, ce qui permet de le convertir assez facilement en une estimation de probabilité ou de confiance du réseau envers le choix de chaque direction.

## Problèmes rencontrés

Le principal problème que l'on a rencontré lors de l'entraînement du réseau et de nos tests en situation est celui de l'overfitting. Nous avons assez vite réussi à atteindre une précision de 89% sur les échantillons d'entraînement, mais lorsque le réseau devait classifier des images qu'il n'avait jamais vu, la précision descendait au début aux alentours de 53%. Les deux facteurs principaux pour ce problème étaient : le petit volume des données d'entraînement, et le fait que notre base de donnée contenait volontairement beaucoup d'images ou le choix à faire était ambigüe. Pour pallier à cela, nous avons utilisé ces solutions : 
	- Nous avons ajouté de nombreuses étapes de drop out au sein de notre entraînement, qui forçait le réseau à prédire des résultats en ignorant une partie des informations aléatoirement à chaque fois, ce qui limite l'influence des outliers et force le réseau à mieux généraliser ses prédictions.
	- Nous avons intégré le système de moyenne mobile, qui ralentit légèrement la vitesse de réaction de notre robot, mais lui permet de ne pas être trop facilement victime de fausses prédictions isolées.
	- Nous avons utilisé des techniques d'augmentation des données (par exemple, nous avons ajouté la version mirroir de chaque image à notre entraînement, ainsi que des versions aux couleurs et à la luminosité altérée)

## Résultats

Au final, nous avons réussi à produire un système qui fonctionne relativement bien malgré la limitation sévère qui était de n'utiliser qu'une seule caméra et de ne pas avoir accès à une "gym" dans laquelle notre robot puisse circuler et améliorer en continu son algorithme. L'une des grandes améliorations a été l'ajout du système de reconnaissance de ligne en amont, ce qui a permis de nous assurer que notre réseau se concentrait uniquement sur les lignes de bord de route pour en déduire la direction à prendre et ne se laissait pas influencer par des artefacts comme la position des objets en arrière plan.
